{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxcxVIIoyjD1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "# Open the zipped folder\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Classroom/Machine Learning (CSL7620) 22-23 Sem II/GurNum-20230429T112325Z-001.zip', 'r') as zip_ref:\n",
        "    # Extract the training data\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    for i in range(10):\n",
        "        folder_name = f'train/{i}/'\n",
        "        for file_name in zip_ref.namelist():\n",
        "            if folder_name in file_name:\n",
        "                with zip_ref.open(file_name) as file:\n",
        "                    img = Image.open(file).convert('L')\n",
        "                    img_arr = np.array(img)\n",
        "                    x_train.append(img_arr)\n",
        "                    y_train.append(i)\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Extract the testing data\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    for i in range(10):\n",
        "        folder_name = f'val/{i}/'\n",
        "        for file_name in zip_ref.namelist():\n",
        "            if folder_name in file_name:\n",
        "                with zip_ref.open(file_name) as file:\n",
        "                    img = Image.open(file).convert('L')\n",
        "                    img_arr = np.array(img)\n",
        "                    x_test.append(img_arr)\n",
        "                    y_test.append(i)\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "# Normalize the features\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD8A7g7iy6yN",
        "outputId": "8c42cf53-7968-45d7-e601-705ffad3a1ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0c7YHOCy9Fs",
        "outputId": "2381aed2-e25d-4a93-e47d-0354356ac546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1., 1., 1., ..., 0., 1., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 0., 0.],\n",
              "        [1., 1., 1., ..., 0., 0., 0.],\n",
              "        [1., 1., 1., ..., 0., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 1.],\n",
              "        [1., 1., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "OcQdp-n_zFAW",
        "outputId": "3b6824b0-c4d7-4da9-b811-d504b792ed37"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to plot a random sample of images\n",
        "def plot_images(images, labels):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(10, 10))\n",
        "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        idx = np.random.randint(0, len(images))\n",
        "        ax.imshow(images[idx], cmap='gray')\n",
        "        ax.set_title(f'Digit: {np.argmax(labels[idx])}')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        \n",
        "# Plot a random sample of five images from the training data\n",
        "plot_images(x_train, y_train)\n",
        "\n",
        "# Plot a random sample of five images from the testing data\n",
        "plot_images(x_test, y_test)\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUUzx8I90edX"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Classroom/Machine Learning (CSL7620) 22-23 Sem II/GurNum-20230429T112325Z-001.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2SY3uGkI3d2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Conv2D, Dropout, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "# Open the zipped folder\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Classroom/Machine Learning (CSL7620) 22-23 Sem II/GurNum-20230429T112325Z-001.zip', 'r') as zip_ref:\n",
        "    # Extract the training data\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    for i in range(10):\n",
        "        folder_name = f'train/{i}/'\n",
        "        for file_name in zip_ref.namelist():\n",
        "            if folder_name in file_name:\n",
        "                with zip_ref.open(file_name) as file:\n",
        "                    img = Image.open(file).convert('L')\n",
        "                    img_arr = np.array(img)\n",
        "                    x_train.append(img_arr)\n",
        "                    y_train.append(i)\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Extract the testing data\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    for i in range(10):\n",
        "        folder_name = f'val/{i}/'\n",
        "        for file_name in zip_ref.namelist():\n",
        "            if folder_name in file_name:\n",
        "                with zip_ref.open(file_name) as file:\n",
        "                    img = Image.open(file).convert('L')\n",
        "                    img_arr = np.array(img)\n",
        "                    x_test.append(img_arr)\n",
        "                    y_test.append(i)\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "# Normalize the features\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "\n",
        "# Data augmentation\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=20, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    horizontal_flip=True\n",
        ")\n",
        "def build_model1(optimizer):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(32, 32))) # Add a Flatten layer to flatten the input images\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# # Define the model\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "# model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guIAG6xGMp8X",
        "outputId": "416cd060-0d2b-4e9b-ab5d-4a77c2c97699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model using Adagrad optimizer\n",
            "Epoch 1/32\n",
            "15/15 [==============================] - 3s 64ms/step - loss: 2.3621 - accuracy: 0.0887 - val_loss: 2.3250 - val_accuracy: 0.1180\n",
            "Epoch 2/32\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 2.3173 - accuracy: 0.1197 - val_loss: 2.2893 - val_accuracy: 0.1348\n",
            "Epoch 3/32\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 2.2778 - accuracy: 0.1357 - val_loss: 2.2632 - val_accuracy: 0.1629\n",
            "Epoch 4/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.2731 - accuracy: 0.1357 - val_loss: 2.2411 - val_accuracy: 0.1461\n",
            "Epoch 5/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.2311 - accuracy: 0.1813 - val_loss: 2.2152 - val_accuracy: 0.1685\n",
            "Epoch 6/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.2085 - accuracy: 0.1806 - val_loss: 2.1842 - val_accuracy: 0.1854\n",
            "Epoch 7/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.1851 - accuracy: 0.1944 - val_loss: 2.1558 - val_accuracy: 0.2416\n",
            "Epoch 8/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.1516 - accuracy: 0.2308 - val_loss: 2.1239 - val_accuracy: 0.2809\n",
            "Epoch 9/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 2.1093 - accuracy: 0.2874 - val_loss: 2.0875 - val_accuracy: 0.3258\n",
            "Epoch 10/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.0938 - accuracy: 0.3226 - val_loss: 2.0564 - val_accuracy: 0.3427\n",
            "Epoch 11/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 2.0556 - accuracy: 0.3312 - val_loss: 2.0207 - val_accuracy: 0.3539\n",
            "Epoch 12/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 2.0232 - accuracy: 0.3739 - val_loss: 1.9830 - val_accuracy: 0.4213\n",
            "Epoch 13/32\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 1.9974 - accuracy: 0.3974 - val_loss: 1.9425 - val_accuracy: 0.4494\n",
            "Epoch 14/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.9463 - accuracy: 0.3996 - val_loss: 1.8998 - val_accuracy: 0.5281\n",
            "Epoch 15/32\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.9080 - accuracy: 0.4295 - val_loss: 1.8606 - val_accuracy: 0.5562\n",
            "Epoch 16/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 1.8677 - accuracy: 0.4583 - val_loss: 1.8205 - val_accuracy: 0.5730\n",
            "Epoch 17/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.8339 - accuracy: 0.4583 - val_loss: 1.7836 - val_accuracy: 0.5506\n",
            "Epoch 18/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.8296 - accuracy: 0.4583 - val_loss: 1.7450 - val_accuracy: 0.6067\n",
            "Epoch 19/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.7724 - accuracy: 0.5075 - val_loss: 1.7048 - val_accuracy: 0.6124\n",
            "Epoch 20/32\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 1.7495 - accuracy: 0.4936 - val_loss: 1.6669 - val_accuracy: 0.6180\n",
            "Epoch 21/32\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 1.7244 - accuracy: 0.5075 - val_loss: 1.6286 - val_accuracy: 0.6404\n",
            "Epoch 22/32\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 1.6660 - accuracy: 0.5385 - val_loss: 1.5955 - val_accuracy: 0.6573\n",
            "Epoch 23/32\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.6291 - accuracy: 0.5353 - val_loss: 1.5558 - val_accuracy: 0.6854\n",
            "Epoch 24/32\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 1.5931 - accuracy: 0.5598 - val_loss: 1.5153 - val_accuracy: 0.6685\n",
            "Epoch 25/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.5850 - accuracy: 0.5395 - val_loss: 1.4809 - val_accuracy: 0.6910\n",
            "Epoch 26/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.5602 - accuracy: 0.5490 - val_loss: 1.4533 - val_accuracy: 0.6854\n",
            "Epoch 27/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 1.5260 - accuracy: 0.5652 - val_loss: 1.4171 - val_accuracy: 0.7191\n",
            "Epoch 28/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.5095 - accuracy: 0.5812 - val_loss: 1.3848 - val_accuracy: 0.6966\n",
            "Epoch 29/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.4789 - accuracy: 0.5705 - val_loss: 1.3538 - val_accuracy: 0.7022\n",
            "Epoch 30/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 1.4437 - accuracy: 0.6026 - val_loss: 1.3258 - val_accuracy: 0.6854\n",
            "Epoch 31/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 1.4179 - accuracy: 0.6100 - val_loss: 1.2970 - val_accuracy: 0.6910\n",
            "Epoch 32/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.3914 - accuracy: 0.6143 - val_loss: 1.2731 - val_accuracy: 0.7191\n",
            "Test accuracy for Adagrad optimizer: 0.7191\n",
            "Training model using Adam optimizer\n",
            "Epoch 1/32\n",
            "15/15 [==============================] - 2s 44ms/step - loss: 2.0742 - accuracy: 0.2660 - val_loss: 1.6347 - val_accuracy: 0.4157\n",
            "Epoch 2/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 1.4854 - accuracy: 0.5053 - val_loss: 1.1304 - val_accuracy: 0.6461\n",
            "Epoch 3/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.1707 - accuracy: 0.6062 - val_loss: 0.8221 - val_accuracy: 0.7360\n",
            "Epoch 4/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 1.0825 - accuracy: 0.6325 - val_loss: 0.6490 - val_accuracy: 0.8090\n",
            "Epoch 5/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.8933 - accuracy: 0.6927 - val_loss: 0.6044 - val_accuracy: 0.8427\n",
            "Epoch 6/32\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 0.8898 - accuracy: 0.6998 - val_loss: 0.5021 - val_accuracy: 0.8258\n",
            "Epoch 7/32\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 0.7640 - accuracy: 0.7479 - val_loss: 0.4308 - val_accuracy: 0.8876\n",
            "Epoch 8/32\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 0.6940 - accuracy: 0.7447 - val_loss: 0.3978 - val_accuracy: 0.8820\n",
            "Epoch 9/32\n",
            "15/15 [==============================] - 1s 81ms/step - loss: 0.6761 - accuracy: 0.7671 - val_loss: 0.4822 - val_accuracy: 0.8315\n",
            "Epoch 10/32\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.6574 - accuracy: 0.7778 - val_loss: 0.3594 - val_accuracy: 0.8989\n",
            "Epoch 11/32\n",
            "15/15 [==============================] - 1s 85ms/step - loss: 0.6467 - accuracy: 0.7788 - val_loss: 0.4934 - val_accuracy: 0.8090\n",
            "Epoch 12/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.6609 - accuracy: 0.7767 - val_loss: 0.4066 - val_accuracy: 0.8652\n",
            "Epoch 13/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.6090 - accuracy: 0.7863 - val_loss: 0.3766 - val_accuracy: 0.9101\n",
            "Epoch 14/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.5561 - accuracy: 0.8120 - val_loss: 0.3005 - val_accuracy: 0.8933\n",
            "Epoch 15/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.5299 - accuracy: 0.8205 - val_loss: 0.4003 - val_accuracy: 0.8483\n",
            "Epoch 16/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.5972 - accuracy: 0.7959 - val_loss: 0.3392 - val_accuracy: 0.8820\n",
            "Epoch 17/32\n",
            "15/15 [==============================] - 1s 32ms/step - loss: 0.5069 - accuracy: 0.8237 - val_loss: 0.5748 - val_accuracy: 0.7753\n",
            "Epoch 18/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.5563 - accuracy: 0.8208 - val_loss: 0.3312 - val_accuracy: 0.8596\n",
            "Epoch 19/32\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.5135 - accuracy: 0.8259 - val_loss: 0.2320 - val_accuracy: 0.9438\n",
            "Epoch 20/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.4995 - accuracy: 0.8376 - val_loss: 0.2835 - val_accuracy: 0.9213\n",
            "Epoch 21/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.5653 - accuracy: 0.7981 - val_loss: 0.3411 - val_accuracy: 0.9045\n",
            "Epoch 22/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.4605 - accuracy: 0.8542 - val_loss: 0.1900 - val_accuracy: 0.9607\n",
            "Epoch 23/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.4374 - accuracy: 0.8665 - val_loss: 0.3067 - val_accuracy: 0.9045\n",
            "Epoch 24/32\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 0.4517 - accuracy: 0.8387 - val_loss: 0.3132 - val_accuracy: 0.9045\n",
            "Epoch 25/32\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 0.4271 - accuracy: 0.8536 - val_loss: 0.3952 - val_accuracy: 0.8708\n",
            "Epoch 26/32\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 0.3679 - accuracy: 0.8803 - val_loss: 0.2012 - val_accuracy: 0.9551\n",
            "Epoch 27/32\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 0.3583 - accuracy: 0.8846 - val_loss: 0.1815 - val_accuracy: 0.9551\n",
            "Epoch 28/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.3863 - accuracy: 0.8761 - val_loss: 0.1991 - val_accuracy: 0.9382\n",
            "Epoch 29/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.4094 - accuracy: 0.8579 - val_loss: 0.1882 - val_accuracy: 0.9494\n",
            "Epoch 30/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.3388 - accuracy: 0.8900 - val_loss: 0.1748 - val_accuracy: 0.9494\n",
            "Epoch 31/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.3705 - accuracy: 0.8814 - val_loss: 0.1952 - val_accuracy: 0.9382\n",
            "Epoch 32/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.3203 - accuracy: 0.9103 - val_loss: 0.1358 - val_accuracy: 0.9551\n",
            "Test accuracy for Adam optimizer: 0.9551\n",
            "Training model using RMSprop optimizer\n",
            "Epoch 1/32\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 2.3376 - accuracy: 0.1453 - val_loss: 2.1847 - val_accuracy: 0.1685\n",
            "Epoch 2/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.0535 - accuracy: 0.2500 - val_loss: 1.7754 - val_accuracy: 0.4101\n",
            "Epoch 3/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.7543 - accuracy: 0.3782 - val_loss: 1.6176 - val_accuracy: 0.3708\n",
            "Epoch 4/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.5742 - accuracy: 0.4199 - val_loss: 1.3618 - val_accuracy: 0.5393\n",
            "Epoch 5/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 1.3996 - accuracy: 0.4882 - val_loss: 1.2378 - val_accuracy: 0.5225\n",
            "Epoch 6/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.2799 - accuracy: 0.5556 - val_loss: 0.9600 - val_accuracy: 0.6067\n",
            "Epoch 7/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.2119 - accuracy: 0.5524 - val_loss: 0.8533 - val_accuracy: 0.7079\n",
            "Epoch 8/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.0551 - accuracy: 0.6271 - val_loss: 1.0160 - val_accuracy: 0.6124\n",
            "Epoch 9/32\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 1.0387 - accuracy: 0.6229 - val_loss: 0.9712 - val_accuracy: 0.6629\n",
            "Epoch 10/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.0134 - accuracy: 0.6303 - val_loss: 0.8274 - val_accuracy: 0.7079\n",
            "Epoch 11/32\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 0.9131 - accuracy: 0.6816 - val_loss: 0.8077 - val_accuracy: 0.6910\n",
            "Epoch 12/32\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 0.8889 - accuracy: 0.6838 - val_loss: 0.8755 - val_accuracy: 0.7022\n",
            "Epoch 13/32\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 0.9332 - accuracy: 0.6581 - val_loss: 0.5467 - val_accuracy: 0.8371\n",
            "Epoch 14/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.8322 - accuracy: 0.6998 - val_loss: 0.7825 - val_accuracy: 0.7360\n",
            "Epoch 15/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.7848 - accuracy: 0.7265 - val_loss: 0.4816 - val_accuracy: 0.8371\n",
            "Epoch 16/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.8131 - accuracy: 0.7179 - val_loss: 0.5437 - val_accuracy: 0.8483\n",
            "Epoch 17/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.8093 - accuracy: 0.7201 - val_loss: 0.6573 - val_accuracy: 0.7697\n",
            "Epoch 18/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.7517 - accuracy: 0.7265 - val_loss: 0.3613 - val_accuracy: 0.9270\n",
            "Epoch 19/32\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.7490 - accuracy: 0.7361 - val_loss: 0.4352 - val_accuracy: 0.9045\n",
            "Epoch 20/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.7504 - accuracy: 0.7415 - val_loss: 0.9525 - val_accuracy: 0.7079\n",
            "Epoch 21/32\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.7825 - accuracy: 0.7188 - val_loss: 0.3589 - val_accuracy: 0.9270\n",
            "Epoch 22/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.6696 - accuracy: 0.7740 - val_loss: 0.7001 - val_accuracy: 0.7753\n",
            "Epoch 23/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.6466 - accuracy: 0.7682 - val_loss: 0.3743 - val_accuracy: 0.8933\n",
            "Epoch 24/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.6337 - accuracy: 0.7735 - val_loss: 0.3665 - val_accuracy: 0.8764\n",
            "Epoch 25/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.6202 - accuracy: 0.7692 - val_loss: 0.3395 - val_accuracy: 0.9045\n",
            "Epoch 26/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.6442 - accuracy: 0.7660 - val_loss: 0.4231 - val_accuracy: 0.8596\n",
            "Epoch 27/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.6217 - accuracy: 0.7895 - val_loss: 0.4232 - val_accuracy: 0.8539\n",
            "Epoch 28/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.5371 - accuracy: 0.8045 - val_loss: 0.3250 - val_accuracy: 0.8989\n",
            "Epoch 29/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.6041 - accuracy: 0.7853 - val_loss: 0.5397 - val_accuracy: 0.8258\n",
            "Epoch 30/32\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 0.5048 - accuracy: 0.8237 - val_loss: 0.3416 - val_accuracy: 0.8820\n",
            "Epoch 31/32\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 0.5500 - accuracy: 0.8152 - val_loss: 0.2134 - val_accuracy: 0.9326\n",
            "Epoch 32/32\n",
            "15/15 [==============================] - 1s 43ms/step - loss: 0.5349 - accuracy: 0.8216 - val_loss: 0.2409 - val_accuracy: 0.9270\n",
            "Test accuracy for RMSprop optimizer: 0.9270\n",
            "Training model using SGD optimizer\n",
            "Epoch 1/32\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 2.3117 - accuracy: 0.1335 - val_loss: 2.2193 - val_accuracy: 0.1685\n",
            "Epoch 2/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.1965 - accuracy: 0.2115 - val_loss: 2.1262 - val_accuracy: 0.3427\n",
            "Epoch 3/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.0976 - accuracy: 0.3521 - val_loss: 2.0203 - val_accuracy: 0.3820\n",
            "Epoch 4/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.0267 - accuracy: 0.3782 - val_loss: 1.9105 - val_accuracy: 0.4775\n",
            "Epoch 5/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.9238 - accuracy: 0.4359 - val_loss: 1.7936 - val_accuracy: 0.5281\n",
            "Epoch 6/32\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 1.8190 - accuracy: 0.4701 - val_loss: 1.6625 - val_accuracy: 0.5393\n",
            "Epoch 7/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.7056 - accuracy: 0.5043 - val_loss: 1.5391 - val_accuracy: 0.6573\n",
            "Epoch 8/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.5969 - accuracy: 0.5323 - val_loss: 1.4163 - val_accuracy: 0.6461\n",
            "Epoch 9/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.4984 - accuracy: 0.5534 - val_loss: 1.3228 - val_accuracy: 0.6348\n",
            "Epoch 10/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 1.4081 - accuracy: 0.5737 - val_loss: 1.2159 - val_accuracy: 0.7360\n",
            "Epoch 11/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.3755 - accuracy: 0.5865 - val_loss: 1.2307 - val_accuracy: 0.6180\n",
            "Epoch 12/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.2953 - accuracy: 0.6015 - val_loss: 1.0624 - val_accuracy: 0.7191\n",
            "Epoch 13/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.2165 - accuracy: 0.6122 - val_loss: 0.9904 - val_accuracy: 0.7191\n",
            "Epoch 14/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 1.1783 - accuracy: 0.6058 - val_loss: 0.9276 - val_accuracy: 0.7360\n",
            "Epoch 15/32\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 1.1440 - accuracy: 0.6314 - val_loss: 0.8932 - val_accuracy: 0.7584\n",
            "Epoch 16/32\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 1.0749 - accuracy: 0.6688 - val_loss: 0.8690 - val_accuracy: 0.7921\n",
            "Epoch 17/32\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 1.0787 - accuracy: 0.6432 - val_loss: 0.8228 - val_accuracy: 0.7584\n",
            "Epoch 18/32\n",
            "15/15 [==============================] - 1s 47ms/step - loss: 1.0480 - accuracy: 0.6677 - val_loss: 0.7416 - val_accuracy: 0.8315\n",
            "Epoch 19/32\n",
            "15/15 [==============================] - 1s 45ms/step - loss: 0.9526 - accuracy: 0.6998 - val_loss: 0.7420 - val_accuracy: 0.7865\n",
            "Epoch 20/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.9767 - accuracy: 0.6827 - val_loss: 0.7183 - val_accuracy: 0.8202\n",
            "Epoch 21/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.9957 - accuracy: 0.6615 - val_loss: 0.7491 - val_accuracy: 0.7978\n",
            "Epoch 22/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.8987 - accuracy: 0.7019 - val_loss: 0.6673 - val_accuracy: 0.8371\n",
            "Epoch 23/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.9052 - accuracy: 0.6979 - val_loss: 0.6494 - val_accuracy: 0.8202\n",
            "Epoch 24/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.9119 - accuracy: 0.6838 - val_loss: 0.6137 - val_accuracy: 0.8371\n",
            "Epoch 25/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.8380 - accuracy: 0.7212 - val_loss: 0.6293 - val_accuracy: 0.8034\n",
            "Epoch 26/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.8537 - accuracy: 0.7222 - val_loss: 0.5775 - val_accuracy: 0.8258\n",
            "Epoch 27/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.8551 - accuracy: 0.7094 - val_loss: 0.6448 - val_accuracy: 0.7809\n",
            "Epoch 28/32\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.8199 - accuracy: 0.7323 - val_loss: 0.5830 - val_accuracy: 0.8371\n",
            "Epoch 29/32\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 0.8283 - accuracy: 0.7190 - val_loss: 0.5391 - val_accuracy: 0.8258\n",
            "Epoch 30/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.8574 - accuracy: 0.7051 - val_loss: 0.5246 - val_accuracy: 0.8539\n",
            "Epoch 31/32\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.7796 - accuracy: 0.7596 - val_loss: 0.4958 - val_accuracy: 0.8539\n",
            "Epoch 32/32\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.7286 - accuracy: 0.7564 - val_loss: 0.5813 - val_accuracy: 0.8034\n",
            "Test accuracy for SGD optimizer: 0.8034\n"
          ]
        }
      ],
      "source": [
        "optimizers = ['Adam', 'RMSprop', 'SGD']\n",
        "accuracies = {}\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    print(f'Training model using {optimizer} optimizer')\n",
        "    model = build_model1(optimizer)\n",
        "    hist =model.fit(datagen_train.flow(x_train.reshape(-1, 32, 32, 1), y_train, batch_size=batch_size),\n",
        "          steps_per_epoch=len(x_train) // batch_size, epochs=32,\n",
        "          validation_data=(x_test.reshape(-1, 32, 32, 1), y_test))\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    accuracies[optimizer] = test_acc\n",
        "    print(f'Test accuracy for {optimizer} optimizer: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFJp5KqsPL-x"
      },
      "outputs": [],
      "source": [
        "model.save(\"GurNum.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}